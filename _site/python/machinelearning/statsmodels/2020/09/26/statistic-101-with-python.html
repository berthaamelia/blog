<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Statistic 101 with python using drilling data | bertha jekyll blog</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Statistic 101 with python using drilling data" />
<meta name="author" content="Author Bertha Amelia" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="I have always loved statistic, it was among my most favorite subject when I did my bachelor and master. In my most recent master thesis, I applied statistical quantitative approach in order to justify the effect of income inequality relative to entrepreneurial activities in 70 different countries. Some people may think it’s boring, but I simply adore how one can generate patterns of information solely from a bunch of numbers in a table form. The more you dig into, the more you discover the hidden layers of information underneath. There is no right or wrong, it is just a question of which method would you like to associate your argument with. Perhaps that is the reason it becomes captivating, the fact that you could not manipulate details inside statistic? It is so pure and honest." />
<meta property="og:description" content="I have always loved statistic, it was among my most favorite subject when I did my bachelor and master. In my most recent master thesis, I applied statistical quantitative approach in order to justify the effect of income inequality relative to entrepreneurial activities in 70 different countries. Some people may think it’s boring, but I simply adore how one can generate patterns of information solely from a bunch of numbers in a table form. The more you dig into, the more you discover the hidden layers of information underneath. There is no right or wrong, it is just a question of which method would you like to associate your argument with. Perhaps that is the reason it becomes captivating, the fact that you could not manipulate details inside statistic? It is so pure and honest." />
<link rel="canonical" href="http://localhost:4000/blog/python/machinelearning/statsmodels/2020/09/26/statistic-101-with-python.html" />
<meta property="og:url" content="http://localhost:4000/blog/python/machinelearning/statsmodels/2020/09/26/statistic-101-with-python.html" />
<meta property="og:site_name" content="bertha jekyll blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-09-26T22:46:00+02:00" />
<script type="application/ld+json">
{"headline":"Statistic 101 with python using drilling data","dateModified":"2020-09-26T22:46:00+02:00","datePublished":"2020-09-26T22:46:00+02:00","author":{"@type":"Person","name":"Author Bertha Amelia"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/blog/python/machinelearning/statsmodels/2020/09/26/statistic-101-with-python.html"},"description":"I have always loved statistic, it was among my most favorite subject when I did my bachelor and master. In my most recent master thesis, I applied statistical quantitative approach in order to justify the effect of income inequality relative to entrepreneurial activities in 70 different countries. Some people may think it’s boring, but I simply adore how one can generate patterns of information solely from a bunch of numbers in a table form. The more you dig into, the more you discover the hidden layers of information underneath. There is no right or wrong, it is just a question of which method would you like to associate your argument with. Perhaps that is the reason it becomes captivating, the fact that you could not manipulate details inside statistic? It is so pure and honest.","@type":"BlogPosting","url":"http://localhost:4000/blog/python/machinelearning/statsmodels/2020/09/26/statistic-101-with-python.html","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/blog/feed.xml" title="bertha jekyll blog" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper">
<!--original title header from minima theme.
    <a class="site-title" rel="author" href="/blog/">bertha jekyll blog</a>
    -->
    <!--Custome: add title and logo header-->
    <a class="site-title" rel="author" href="/blog/"><img src="/blog/images/title-logo.png" alt=" bertha jekyll blog">
    <!-- end of title & logo--><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger">
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewbox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"></path>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About</a></div>
      </nav></a>
</div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Statistic 101 with python using drilling data</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2020-09-26T22:46:00+02:00" itemprop="datePublished">Sep 26, 2020
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>I have always loved statistic, it was among my most favorite subject when I did my bachelor and master. In my most recent master thesis, I applied statistical quantitative approach in order to justify the effect of income inequality relative to entrepreneurial activities in 70 different countries. 
Some people may think it’s boring, but I simply adore how one can generate patterns of information solely from a bunch of numbers in a table form. The more you dig into, the more you discover the hidden layers of information underneath. There is no right or wrong, it is just a question of which method would you like to associate your argument with. Perhaps that is the reason it becomes captivating, the fact that you could not manipulate details inside statistic? It is so pure and honest.</p>

<p>Back in university, I normally used SPSS package to run statistical analysis. Now that I don’t own any license of it, I challenged myself to use python instead. It is not easy at all obviously, however i believe it is the learning process that matter. Here I would like to share with you my starting journey of statistical analysis with python library in statistic such as Sci-kit and Matplotlib. Statsmodels comes handy too when it comes to advanced statistic. I will apply all these library in the study case to give general idea of how python can be used to interpret statistical data <img class="emoji" title=":chart_with_upwards_trend:" alt=":chart_with_upwards_trend:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4c8.png" height="20" width="20">.</p>

<h2 id="basic-linear-regression-step-by-step">Basic linear regression step-by-step</h2>
<h3 id="1-create-a-scatter-plot">1. Create a scatter-plot</h3>
<p>In order to establish an assumption, we must first identify a scenario where our independent variable could potentially impose a positive or negative relationship to our dependent variable. One of the easiest way to find such relationship is by recognizing the trend exists in a scatter plot. 
<br>I plotted few random drilling parameters taken from a dummy well. The file is originally in .LAS then I converted and prepared it in .xlsx format hence we can utilize dataframe pandas to read the excel file. In this case, I would like to test hypothesis that Rate of Penetration (ROP) is directly depending on the Rotation per Minute (RPM) and Weight on Bit (WOB).</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center"><img src="https://raw.githubusercontent.com/berthaamelia/blog/master/images/linear_stat_formula.png" alt="Fundamental linear regression equation"></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><em>Courtesy from https://towardsdatascience.com/linear-regression-in-python-9a1f5f000606</em></td>
    </tr>
  </tbody>
</table>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s">"/Users/berthaamelia/Documents/Python/sample/dummy_well.xlsx"</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s">"DATETIME"</span><span class="p">]</span><span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">"DATETIME"</span><span class="p">])</span>

<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">211</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">"Bit_Weight"</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s">"ROP_-_Average"</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s">"DHT001_Depth"</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span> <span class="s">"colorbar=DHT001 Depth"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"surface WOB vs. ROP"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">colorbar</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">212</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">"Top_Drive_RPM"</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s">"ROP_-_Average"</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s">"DHT001_Depth"</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"surface RPM vs. ROP"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">colorbar</span><span class="p">()</span>
</code></pre></div></div>
<p><img src="https://raw.githubusercontent.com/berthaamelia/blog/master/images/scatterplot.png" alt="Scatterplot"></p>

<p>The number (211) refers to no.of row=2, no.of column=1 and the last digit is where you want to place your current plot.
Matplotlib.pyplot receives parameters as such:
<br>x= x-axis (surface WOB and RPM)
<br>y= y-axis (ROP)
<br>s= size 
<br>c= color
<br>alpha = 0.5 (transparency).
<br>I am using the channel “Hole Depth” as the colorscale. You can as well play around with different colorscale, you may also assign a channel as the size reference too.</p>

<h3 id="2-establish-simple-linear-regression-chart">2. Establish simple linear regression chart</h3>
<p>As we see in the scatter-plot above, there seems to be a cluster of data towards the ROP. Although it is not exclusively apparent, we may want to establish a linear regression model to test whether our hypothesis is statistically significant or not. To do so I will use the module sklearn and import its linear model.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">sns</span><span class="p">.</span><span class="n">set_style</span><span class="p">(</span><span class="s">"whitegrid"</span><span class="p">)</span> <span class="c1">#Use seaborns module for better visualisation
</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s">"/Users/berthaamelia/Documents/Python/sample/dummy_well.xlsx"</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>

<span class="c1">#Convert all data into numpy 2-dimensional
</span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">"Bit_Weight"</span><span class="p">]).</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">"Top_Drive_RPM"</span><span class="p">]).</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">"ROP_-_Average"</span><span class="p">])</span>

<span class="n">model_WOB</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">().</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">model_RPM</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">().</span><span class="n">fit</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">r_sq_WOB</span> <span class="o">=</span> <span class="n">model_WOB</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">r_sq_RPM</span> <span class="o">=</span> <span class="n">model_RPM</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1">#Print R-squared, gradient and intercept values for each regression
</span><span class="k">print</span><span class="p">(</span><span class="s">'coefficient of determination:'</span><span class="p">,</span> <span class="n">r_sq_WOB</span><span class="p">)</span> <span class="c1">#This is R-squared
</span><span class="k">print</span><span class="p">(</span><span class="s">'intercept:'</span><span class="p">,</span> <span class="n">model_WOB</span><span class="p">.</span><span class="n">intercept_</span><span class="p">)</span> <span class="c1">#This represents B0
</span><span class="k">print</span><span class="p">(</span><span class="s">'slope:'</span><span class="p">,</span> <span class="n">model_WOB</span><span class="p">.</span><span class="n">coef_</span><span class="p">)</span> <span class="c1">#This represents the slope, or coefficient B1
</span>
<span class="k">print</span><span class="p">(</span><span class="s">'coefficient of determination:'</span><span class="p">,</span> <span class="n">r_sq_RPM</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'intercept:'</span><span class="p">,</span> <span class="n">model_RPM</span><span class="p">.</span><span class="n">intercept_</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'slope:'</span><span class="p">,</span> <span class="n">model_RPM</span><span class="p">.</span><span class="n">coef_</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span><span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">regplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">"Bit_Weight"</span><span class="p">],</span><span class="n">y</span><span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">"ROP_-_Average"</span><span class="p">],</span> <span class="n">data</span><span class="o">=</span> <span class="n">df</span><span class="p">,</span><span class="n">scatter_kws</span><span class="o">=</span><span class="p">{</span><span class="s">'alpha'</span><span class="p">:</span><span class="mf">0.5</span><span class="p">},</span> <span class="n">line_kws</span><span class="o">=</span><span class="p">{</span><span class="s">'color'</span><span class="p">:</span> <span class="s">'red'</span><span class="p">},</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sns</span><span class="p">.</span><span class="n">regplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">"Top_Drive_RPM"</span><span class="p">],</span><span class="n">y</span><span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">"ROP_-_Average"</span><span class="p">],</span> <span class="n">data</span><span class="o">=</span> <span class="n">df</span><span class="p">,</span><span class="n">scatter_kws</span><span class="o">=</span><span class="p">{</span><span class="s">'alpha'</span><span class="p">:</span><span class="mf">0.5</span><span class="p">},</span> <span class="n">line_kws</span><span class="o">=</span><span class="p">{</span><span class="s">'color'</span><span class="p">:</span> <span class="s">'red'</span><span class="p">},</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p><img src="https://raw.githubusercontent.com/berthaamelia/blog/master/images/regressionplot.png" alt="Linear regression plot"></p>

<p><br> Result for surface WOB:</p>

<table>
  <thead>
    <tr>
      <th>coefficient of determination (R<sup>2</sup>)</th>
      <th>0.11853302650679276</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>intercept (β<sub>0</sub>)</td>
      <td>12.077543082954572</td>
    </tr>
    <tr>
      <td>slope (β<sub>1</sub>)</td>
      <td>0.27129165</td>
    </tr>
  </tbody>
</table>

<p><br>Result for surface RPM:</p>

<table>
  <thead>
    <tr>
      <th>coefficient of determination (R<sup>2</sup>)</th>
      <th>0.18675176285206874</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>intercept (β<sub>0</sub>)</td>
      <td>11.41033600398227</td>
    </tr>
    <tr>
      <td>slope (β<sub>1</sub>)</td>
      <td>0.09560672</td>
    </tr>
  </tbody>
</table>

<h3 id="3-predict-response-using-training-set">3. Predict response using training set</h3>
<p>Now that we have generated our linear regression model, we proceed with testing the model using some random data. For this purpose we will need to split the data, we will use 80% of total data for training dataset and 20% for testing dataset. 
<br>Let us first test the regression model one by one in order to avoid confusion when coding. Start with the first model where surface WOB is the independent variable and ROP is our dependent variable, we want to test whether the model is sufficient enough to predict ROP average based on WOB parameter. Then we will compare the result with another model where surface RPM is the predictor.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plot</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">sns</span><span class="p">.</span><span class="n">set_style</span><span class="p">(</span><span class="s">"whitegrid"</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s">"/Users/berthaamelia/Documents/Python/sample/dummy_well.xlsx"</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s">"DATETIME"</span><span class="p">]</span><span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">"DATETIME"</span><span class="p">])</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">"Bit_Weight"</span><span class="p">]).</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="c1">#reshape into 2-D numpy data
</span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">"ROP_-_Average"</span><span class="p">])</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">xTrain</span><span class="p">,</span> <span class="n">xTest</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">,</span> <span class="n">yTest</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1">#Here we assign 20% of total data as test dataset &amp; 
#80% as train dataset
</span>
<span class="n">linearRegressor</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">linearRegressor</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xTrain</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">)</span>

<span class="n">yPrediction</span> <span class="o">=</span> <span class="n">linearRegressor</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xTest</span><span class="p">)</span>

<span class="n">plot</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xTrain</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s">'blue'</span><span class="p">)</span>
<span class="n">plot</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xTrain</span><span class="p">,</span> <span class="n">linearRegressor</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xTrain</span><span class="p">),</span> <span class="n">color</span> <span class="o">=</span> <span class="s">'red'</span><span class="p">)</span>
<span class="n">plot</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'ROP vs. WOB (Training set)'</span><span class="p">)</span>
<span class="n">plot</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'WOB'</span><span class="p">)</span>
<span class="n">plot</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'ROP Average'</span><span class="p">)</span>
<span class="n">plot</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">plot</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xTest</span><span class="p">,</span> <span class="n">yTest</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s">'orange'</span><span class="p">)</span>
<span class="n">plot</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xTrain</span><span class="p">,</span> <span class="n">linearRegressor</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xTrain</span><span class="p">),</span> <span class="n">color</span> <span class="o">=</span> <span class="s">'red'</span><span class="p">)</span>
<span class="n">plot</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'ROP vs. WOB (Test set)'</span><span class="p">)</span>
<span class="n">plot</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'WOB'</span><span class="p">)</span>
<span class="n">plot</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'ROP average'</span><span class="p">)</span>
<span class="n">plot</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p><img src="https://raw.githubusercontent.com/berthaamelia/blog/master/images/Trainingset_WOB.png" alt="Training set WOB to predict ROP average">
<img src="https://raw.githubusercontent.com/berthaamelia/blog/master/images/Testset_WOB.png" alt="Test set WOB to predict ROP average"></p>

<p><br>Now if we want to print the first five values of our x-test data and generate the predicted-y, we can add the following line:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">"X=%s, Predicted=%s"</span> <span class="o">%</span> <span class="p">(</span><span class="n">xTest</span><span class="p">[:</span><span class="mi">5</span><span class="p">],</span> <span class="n">yPrediction</span><span class="p">[:</span><span class="mi">5</span><span class="p">]))</span>
<span class="c1">#It will print out:
#/usr/local/bin/python3.7 /Users/berthaamelia/Documents/#Python/sample/linear_reg.py
#X=[[11.6]
# [ 7.8]
# [23. ]
# [22.6]
# [20.3]], Predicted=[15.25509899 14.21339632 18.380207   18.27055409 17.#64004984]
</span></code></pre></div></div>
<p>This implies, when WOB is 11.6, the ROP average is estimated to be 15.25 based on current model.
How good is our model actually as compared to the real y-values? Here we can try to display the comparison between actual vs. predicted y-values in dataframe format.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_test</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s">'Actual'</span><span class="p">:</span> <span class="n">yTest</span><span class="p">,</span> <span class="s">'Predicted'</span><span class="p">:</span> <span class="n">yPrediction</span><span class="p">})</span>
<span class="c1">#It will print out:
#       Actual  Predicted
#0       2.93  15.255099
#1       5.98  14.213396
#2      19.16  18.380207
#3       4.62  18.270554
#4      10.28  17.640050
#...      ...        ...
#4601   12.88  16.680587
#4602    3.22  12.212231
#4603   14.63  13.774785
#4604   14.60  12.075165
#4605   21.73  13.226520
#
#[4606 rows x 2 columns]
</span></code></pre></div></div>
<p>Now let us generate training and testing data set for topdrive RPM data. 
In this case, it will be exactly the same block code as writtent above, the difference is we change x variable into “Top Drive RPM”.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">"Top_Drive_RPM"</span><span class="p">]).</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">"ROP_-_Average"</span><span class="p">])</span>
</code></pre></div></div>
<p><img src="https://raw.githubusercontent.com/berthaamelia/blog/master/images/Trainingset_RPM.png" alt="Training set topdrive RPM to predict ROP average">
<img src="https://raw.githubusercontent.com/berthaamelia/blog/master/images/Testset_RPM.png" alt="Test set topdrive RPM to predict ROP average"></p>

<h3 id="4-determining-error">4. Determining error</h3>
<p>Now that we have run brief analysis on both our predictors: WOB and topdrive RPM to estimate the average ROP, we need to evaluate the performance of our algorithm on particular dataset. It would be hard to judge simply by looking at the difference in predicted-y values on both predictors. Thus, an easier way to asses which model performs better is by looking at the error. To do that, we will use the evaluation metrics module from sklearn.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Mean Absolute Error:'</span><span class="p">,</span> <span class="n">metrics</span><span class="p">.</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">yTest</span><span class="p">,</span> <span class="n">yPrediction</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Mean Squared Error:'</span><span class="p">,</span> <span class="n">metrics</span><span class="p">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">yTest</span><span class="p">,</span> <span class="n">yPrediction</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Root Mean Squared Error:'</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">metrics</span><span class="p">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">yTest</span><span class="p">,</span> <span class="n">yPrediction</span><span class="p">)))</span>
</code></pre></div></div>
<p>For surface WOB:
<br>Mean Absolute Error: 4.125982092922794
<br>Mean Squared Error: 35.622605808248416
<br>Root Mean Squared Error: 5.968467626472344</p>

<p>For topdrive RPM:
<br>Mean Absolute Error: 3.7542304735761456
<br>Mean Squared Error: 32.938404440623884
<br>Root Mean Squared Error: 5.73919893718835</p>

<h4 id="interpretation-of-regression-results">Interpretation of regression results</h4>

<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Interpretation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>R<sup>2</sup>
</td>
      <td>Reflects the fit of the model. R-squared values range from 0 to 1, where a higher value generally indicates a better fit, assuming certain conditions are met.</td>
    </tr>
    <tr>
      <td>Intercept</td>
      <td>It means that when surface WOB or surface RPM coefficients are zero, then the expected output (i.e., the average ROP) would be equal to the const coefficient.</td>
    </tr>
    <tr>
      <td>Slope</td>
      <td>It represents the change in the output Y due to a change of one unit in the interest rate (everything else held constant</td>
    </tr>
  </tbody>
</table>

<p><br>Mean Absolute Error (MAE) is the mean of the absolute value of the errors. This is simply calculating mean of the difference between prediction and actual observation.
<br>Mean Squared Error (MSE) is the mean of the squared errors
<br>Root Mean Squared Error (RMSE) is the square root of the mean of the squared errors. This is the most popular metric and commonly used to interpret statistical data error. The topdrive RPM RMSE is slightly less than WOB, implying the predicted-y values for RPM are closer to the actual values, thus suggesting a better fit regression  than WOB.</p>

<h3 id="5-extra-advanced-linear-regression-with-statsmodels">5. [Extra] Advanced linear regression with statsmodels</h3>
<p>If you fancy SPSS just like me, you would appreciate the statsmodels package in python library. It provides a more comprehensive result and sophisticated look as compared to traditional scikit. Here is the example of runing statsmodels linear regression using the same data set for surface WOB.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="n">sm</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s">"/Users/berthaamelia/Documents/Python/sample/dummy_well.xlsx"</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s">"DATETIME"</span><span class="p">]</span><span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">"DATETIME"</span><span class="p">])</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">"Bit_Weight"</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">"ROP_-_Average"</span><span class="p">]</span>

<span class="c1">#add constant to X
</span><span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">x</span><span class="p">).</span><span class="n">fit</span><span class="p">()</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">summary</span><span class="p">())</span>
</code></pre></div></div>

<p><br>Now if we compare the statistical results from statsmodels with scikit library, we obtained exactly the same results. R-squared is 0.119, const refers to the intercept which is 12.0775 and Bit_Weight refers to the slope which is 0.2713.
<img src="https://raw.githubusercontent.com/berthaamelia/blog/master/images/statsmodels_WOB.png" alt="statsmodels result for surface WOB"></p>

<p><br>
Reading source:
<br><a href="https://www.kdnuggets.com/2019/03/beginners-guide-linear-regression-python-scikit-learn.html">https://www.kdnuggets.com/2019/03/beginners-guide-linear-regression-python-scikit-learn.html</a>
<br><a href="https://stackabuse.com/linear-regression-in-python-with-scikit-learn/">https://stackabuse.com/linear-regression-in-python-with-scikit-learn/</a></p>

  </div>
<a class="u-url" href="/blog/python/machinelearning/statsmodels/2020/09/26/statistic-101-with-python.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">bertha jekyll blog</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Author Bertha Amelia</li>
<li><a class="u-email" href="mailto:berthaamelia@gmail.com">berthaamelia@gmail.com</a></li>
<li>© Bertha Jekyll Blog 2020</li>
</ul>
      </div>

      <div class="footer-col footer-col-2">
<ul class="social-media-list">
<li><a href="https://www.facebook.com/bertha.amelia.35"><svg class="svg-icon"><use xlink:href="/blog/assets/minima-social-icons.svg#facebook"></use></svg> <span class="username">bertha.amelia.35</span></a></li>
<li><a href="https://github.com/berthaamelia"><svg class="svg-icon"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg> <span class="username">berthaamelia</span></a></li>
<li><a href="https://www.linkedin.com/in/bertha-amelia-6b23b878"><svg class="svg-icon"><use xlink:href="/blog/assets/minima-social-icons.svg#linkedin"></use></svg> <span class="username">bertha-amelia-6b23b878</span></a></li>
</ul>
</div>

      <div class="footer-col footer-col-3">
        <p>Welcome! This is my first blog that i build from scratch with jekyll. Most of contents are about my boring life &amp; some are about programming contents that i found interesting to share it with you.</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
